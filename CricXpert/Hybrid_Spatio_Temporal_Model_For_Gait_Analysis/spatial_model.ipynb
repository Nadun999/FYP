{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting frames from the video clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_folder, player_name, num_frames=20):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = total_frames // num_frames if total_frames > num_frames else 1\n",
    "\n",
    "    video_basename = os.path.splitext(os.path.basename(video_path))[0]  # Get video file name without extension\n",
    "    player_folder = os.path.join(output_folder, player_name)\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(player_folder):\n",
    "            os.makedirs(player_folder)\n",
    "    except OSError:\n",
    "        print(f\"Error: Creating directory {player_folder}\")\n",
    "\n",
    "    frame_ids = [int(interval * i) for i in range(num_frames)]\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "\n",
    "    while saved_frames < num_frames:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_ids[saved_frames])\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(f\"Failed to read frame at index {frame_ids[saved_frames]} from {video_path}\")\n",
    "            saved_frames += 1\n",
    "            continue\n",
    "\n",
    "        frame_path = os.path.join(player_folder, f\"{video_basename}_frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        saved_frames += 1\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the extracted frames and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(root_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "\n",
    "    # Iterate through each player's folder to load images\n",
    "    for player_name in os.listdir(root_folder):\n",
    "        player_folder = os.path.join(root_folder, player_name)\n",
    "        if os.path.isdir(player_folder):\n",
    "            for img_file in os.listdir(player_folder):\n",
    "                if img_file.lower().endswith(valid_extensions):\n",
    "                    img_path = os.path.join(player_folder, img_file)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        print(f\"Warning: Could not read image {img_path} - it may be corrupt or in an unsupported format.\")\n",
    "                        continue\n",
    "\n",
    "                    # img = cv2.resize(img, (64, 64))\n",
    "                    img = cv2.resize(img, (128, 128))  # Resize for MobileNetV2\n",
    "                    images.append(img)\n",
    "                    labels.append(player_name)  # Label is the player's name\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Encode labels to integers\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    categorical_labels = to_categorical(encoded_labels)  # One-hot encoding\n",
    "\n",
    "    num_images = len(images)\n",
    "    print(f\"Number of loaded and preprocessed frames: {num_images}\")\n",
    "    return images, categorical_labels, encoder, num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(num_classes):\n",
    "#     model = Sequential([\n",
    "#         Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Conv2D(64, (3, 3), activation='relu'),\n",
    "#         MaxPooling2D(2, 2),\n",
    "#         Flatten(),\n",
    "#         Dense(128, activation='relu'),\n",
    "#         Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "    \n",
    "#     model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "def build_model(num_classes):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False  # Freeze the layers of the base model\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded and preprocessed frames: 1749\n",
      "Epoch 1/10\n",
      "55/55 [==============================] - 5s 70ms/step - loss: 1.6650 - accuracy: 0.4260\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 4s 64ms/step - loss: 1.0030 - accuracy: 0.6810\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 0.7464 - accuracy: 0.7759\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 0.5230 - accuracy: 0.8553\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 0.4222 - accuracy: 0.8902\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 0.3282 - accuracy: 0.9291\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 4s 65ms/step - loss: 0.2560 - accuracy: 0.9485\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 4s 66ms/step - loss: 0.1983 - accuracy: 0.9708\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 4s 71ms/step - loss: 0.1767 - accuracy: 0.9703\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 4s 66ms/step - loss: 0.1536 - accuracy: 0.9754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    root_folder = '/Users/nadunsenarathne/Downloads/Documents/IIT/4th Year/FYP/CricXpert/Datasets/India'\n",
    "    output_frame_folder = '/Users/nadunsenarathne/Downloads/Documents/IIT/4th Year/FYP/CricXpert/Hybrid_Spatio_Temporal_Model_For_Gait_Analysis/extracted_frames'\n",
    "    video_extensions = ('.mp4', '.avi', '.mov', '.mpeg', '.mpg', '.mkv')\n",
    "\n",
    "    # for player_name in os.listdir(root_folder):\n",
    "    #     player_path = os.path.join(root_folder, player_name, 'gait_data')\n",
    "    #     if os.path.isdir(player_path):\n",
    "    #         print(f\"Processing videos for player: {player_name}\")\n",
    "    #         for video_file in os.listdir(player_path):\n",
    "    #             if video_file.endswith(video_extensions):\n",
    "    #                 video_path = os.path.join(player_path, video_file)\n",
    "    #                 print(f\"Extracting frames from: {video_path}\")\n",
    "    #                 extract_frames(video_path, output_frame_folder, player_name, 20)\n",
    "    #             else:\n",
    "    #                 print(f\"Skipped non-video file: {video_file}\")\n",
    "\n",
    "\n",
    "    # Load and preprocess data\n",
    "    X_train, y_train, encoder, num_images = load_and_preprocess_data(output_frame_folder)\n",
    " \n",
    "    # Build and train model\n",
    "    model = build_model(len(encoder.classes_))  # Ensure the model is built for the correct number of classes\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    # Save the model and label encoder\n",
    "    model.save('spatial_model.h5')\n",
    "    np.save('label_encoder_classes.npy', encoder.classes_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 396ms/step\n",
      "The player in the video is: Virat_Kohli\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to extract frames\n",
    "def extract_frames_for_prediction(video_path, output_folder, num_frames=20):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = total_frames // num_frames if total_frames > num_frames else 1\n",
    "    frame_ids = [int(interval * i) for i in range(num_frames)]\n",
    "    frames = []\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "    except OSError:\n",
    "        print(f\"Error: Creating directory {output_folder}\")\n",
    "\n",
    "    frame_count = 0\n",
    "    while frame_count < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count in frame_ids:\n",
    "            resized_frame = cv2.resize(frame, (128, 128))  # Resize frame as per training\n",
    "            frames.append(resized_frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_model('spatial_model.h5')\n",
    "\n",
    "# Properly load the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('label_encoder_classes.npy', allow_pickle=True)\n",
    "\n",
    "# Prediction function\n",
    "def predict_player(video_path):\n",
    "    frame_folder = 'temp_frames'\n",
    "    frames = extract_frames_for_prediction(video_path, frame_folder)\n",
    "    if len(frames) == 0:\n",
    "        return \"No frames to analyze.\"\n",
    "\n",
    "    predictions = model.predict(frames)\n",
    "    predicted_class = np.argmax(np.mean(predictions, axis=0))\n",
    "    predicted_player = encoder.inverse_transform([predicted_class])[0]  # Translate label index back to player name\n",
    "\n",
    "    return predicted_player\n",
    "\n",
    "# Example usage\n",
    "video_path = '/Users/nadunsenarathne/Downloads/Documents/IIT/4th Year/FYP/CricXpert/Datasets/untitled folder/2.mov'  # Path to your test video clip\n",
    "result = predict_player(video_path)\n",
    "print(f\"The player in the video is: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
