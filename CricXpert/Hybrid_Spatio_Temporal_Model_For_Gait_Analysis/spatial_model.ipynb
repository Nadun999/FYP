{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 65.2288 - accuracy: 0.2041\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 1.1610 - accuracy: 0.6029\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.4360 - accuracy: 0.8612\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.2101 - accuracy: 0.9410\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.1057 - accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.1950 - accuracy: 0.9681\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.1641 - accuracy: 0.9633\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.1573 - accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.1094 - accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.1831 - accuracy: 0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def extract_frames(video_path, output_folder, num_frames=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = total_frames // num_frames if total_frames > num_frames else 1\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "    except OSError:\n",
    "        print(f\"Error: Creating directory {output_folder}\")\n",
    "\n",
    "    frame_ids = [int(interval * i) for i in range(num_frames)]\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "\n",
    "    while saved_frames < num_frames:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_ids[saved_frames])\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            print(f\"Failed to read frame at index {frame_ids[saved_frames]} from {video_path}\")\n",
    "            saved_frames += 1\n",
    "            continue\n",
    "\n",
    "        if frame is None or frame.size == 0:\n",
    "            print(f\"Warning: Empty or corrupt frame at index {frame_ids[saved_frames]} in {video_path}\")\n",
    "            saved_frames += 1\n",
    "            continue\n",
    "\n",
    "        frame_path = os.path.join(output_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        saved_frames += 1\n",
    "        frame_count = frame_ids[saved_frames] if saved_frames < num_frames else frame_count\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(root_folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    valid_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\")\n",
    "\n",
    "    # Iterate through each player's folder to load images\n",
    "    for player_name in os.listdir(root_folder):\n",
    "        player_folder = os.path.join(root_folder, player_name)\n",
    "        if os.path.isdir(player_folder):\n",
    "            for img_file in os.listdir(player_folder):\n",
    "                if img_file.lower().endswith(valid_extensions):\n",
    "                    img_path = os.path.join(player_folder, img_file)\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        print(f\"Warning: Could not read image {img_path} - it may be corrupt or in an unsupported format.\")\n",
    "                        continue\n",
    "\n",
    "                    img = cv2.resize(img, (64, 64))\n",
    "                    images.append(img)\n",
    "                    labels.append(player_name)  # Label is the player's name\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Encode labels to integers\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_labels = encoder.fit_transform(labels)\n",
    "    categorical_labels = to_categorical(encoded_labels)  # One-hot encoding\n",
    "\n",
    "    return images, categorical_labels, encoder\n",
    "\n",
    "def build_model(num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    output_frame_folder = '/Users/nadunsenarathne/Downloads/Documents/IIT/4th Year/FYP/CricXpert/Hybrid_Spatio_Temporal_Model_For_Gait_Analysis/extracted_frames'\n",
    "\n",
    "    X_train, y_train, encoder = load_and_preprocess_data(output_frame_folder)\n",
    "    model = build_model(len(encoder.classes_))\n",
    "    model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "    model.save('player_recognition_model.h5')\n",
    "    np.save('label_encoder_classes.npy', encoder.classes_)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "The player in the video is: Hardik_Pandya\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to extract frames\n",
    "def extract_frames_for_prediction(video_path, output_folder, num_frames=10):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    interval = total_frames // num_frames\n",
    "    frame_ids = [int(interval * i) for i in range(num_frames)]\n",
    "    frames = []\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "    except OSError:\n",
    "        print(f\"Error: Creating directory {output_folder}\")\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count in frame_ids:\n",
    "            resized_frame = cv2.resize(frame, (64, 64))\n",
    "            frames.append(resized_frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Load the model and label encoder\n",
    "model = load_model('player_recognition_model.h5')\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load('label_encoder_classes.npy')\n",
    "\n",
    "# Prediction function\n",
    "def predict_player(video_path):\n",
    "    frame_folder = 'temp_frames'\n",
    "    frames = extract_frames_for_prediction(video_path, frame_folder)\n",
    "    predictions = model.predict(frames)\n",
    "    predicted_class = np.argmax(np.mean(predictions, axis=0))\n",
    "    predicted_player = encoder.inverse_transform([predicted_class])[0]  # Translate label index back to player name\n",
    "\n",
    "    return predicted_player\n",
    "\n",
    "# Example usage\n",
    "video_path = '/Users/nadunsenarathne/Downloads/Documents/IIT/4th Year/FYP/CricXpert/Datasets/untitled folder/1.mov'  # Path to your test video clip\n",
    "result = predict_player(video_path)\n",
    "print(f\"The player in the video is: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
